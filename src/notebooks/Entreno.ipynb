{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import precision_score , classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos nuestro dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('wineclean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='quality')\n",
    "y = df['quality']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos nuestro dataset para el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escalamos con robust escaler para eliminar outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = RobustScaler(with_centering=True, with_scaling=True, quantile_range=(25.0, 75.0), copy=True,).fit_transform(X_test)\n",
    "X_train = RobustScaler(with_centering=True, with_scaling=True, quantile_range=(25.0, 75.0), copy=True,).fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escalamos con standarscaler para normalizar nuestros valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Clasiffier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train 0.8434132394985705\n",
      "Accuracy test 0.8307692307692308\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.21      0.32       365\n",
      "           1       0.84      0.97      0.90      1585\n",
      "\n",
      "    accuracy                           0.83      1950\n",
      "   macro avg       0.74      0.59      0.61      1950\n",
      "weighted avg       0.81      0.83      0.79      1950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rnd_clf = RandomForestClassifier(n_estimators=500,\n",
    "                                 max_leaf_nodes=16,\n",
    "                                 random_state=42,\n",
    "                                    \n",
    "                                )\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rnd_clf.predict(X_test)\n",
    "print(\"Accuracy train\",rnd_clf.score(X_train, y_train))\n",
    "print(\"Accuracy test\",rnd_clf.score(X_test, y_test))\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Clasiffier hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 800,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_depth': 15}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestClassifier(random_state = 42)\n",
    "n_estimators = [100, 300, 500, 800, 1200]\n",
    "max_depth = [5, 8, 15, 25, 30]\n",
    "min_samples_split = [2, 5, 10, 15, 100]\n",
    "min_samples_leaf = [1, 2, 5, 10]\n",
    "max_leaf_nodes = [8,10,14,16,20]\n",
    "\n",
    "hyperF = dict(n_estimators = n_estimators, max_depth = max_depth,  \n",
    "              min_samples_split = min_samples_split, \n",
    "             min_samples_leaf = min_samples_leaf,)\n",
    "\n",
    "gridF = RandomizedSearchCV(forest, hyperF, cv = 10, verbose = 1, \n",
    "                      n_jobs = -1)\n",
    "bestF = gridF.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "bestF.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train 0.9923026171101825\n",
      "Accuracy test 0.8676923076923077\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.48      0.58       365\n",
      "           1       0.89      0.96      0.92      1585\n",
      "\n",
      "    accuracy                           0.87      1950\n",
      "   macro avg       0.80      0.72      0.75      1950\n",
      "weighted avg       0.86      0.87      0.86      1950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rnd_clf = RandomForestClassifier(n_estimators=800,\n",
    " min_samples_split=5,\n",
    " min_samples_leaf =1,\n",
    " max_depth = 25)\n",
    "                                    \n",
    "                                \n",
    "rnd_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rnd_clf.predict(X_test)\n",
    "print(\"Accuracy train\",rnd_clf.score(X_train, y_train))\n",
    "print(\"Accuracy test\",rnd_clf.score(X_test, y_test))\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train 0.8865185836815482\n",
      "Accuracy test 0.8364102564102565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.47      0.52       365\n",
      "           1       0.88      0.92      0.90      1585\n",
      "\n",
      "    accuracy                           0.84      1950\n",
      "   macro avg       0.73      0.70      0.71      1950\n",
      "weighted avg       0.83      0.84      0.83      1950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "\n",
    "print(\"Accuracy train\",knn.score(X_train, y_train))\n",
    "print(\"Accuracy test\",knn.score(X_test, y_test))\n",
    "print(classification_report(y_test, y_pred_knn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "0.8709076826257443\n",
      "{'weights': 'distance', 'p': 2, 'n_neighbors': 16, 'leaf_size': 35, 'algorithm': 'auto'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vecinos = KNeighborsClassifier()\n",
    "\n",
    "n_neighbors = [2,4,6,8,10,12,14,16,20]\n",
    "weights = ['uniform', 'distance']\n",
    "algorithm = ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "leaf_size = [15,20,25,30,35,40,45]\n",
    "p = [1,2]\n",
    "hyperF = dict(n_neighbors=n_neighbors,weights=weights,algorithm=algorithm,leaf_size=leaf_size,p=p)\n",
    "\n",
    "gridF = RandomizedSearchCV(vecinos, hyperF, cv = 10, verbose = 1, \n",
    "                      n_jobs = -1)\n",
    "bestF = gridF.fit(X_train, y_train)\n",
    "\n",
    "print(bestF.best_score_)\n",
    "print(bestF.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train 1.0\n",
      "Accuracy test 0.857948717948718\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.47      0.55       365\n",
      "           1       0.89      0.95      0.92      1585\n",
      "\n",
      "    accuracy                           0.86      1950\n",
      "   macro avg       0.78      0.71      0.73      1950\n",
      "weighted avg       0.85      0.86      0.85      1950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(weights='distance', p=2, n_neighbors=20, leaf_size=40, algorithm='brute')\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "\n",
    "print(\"Accuracy train\",knn.score(X_train, y_train))\n",
    "print(\"Accuracy test\",knn.score(X_test, y_test))\n",
    "print(classification_report(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:27:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy train 0.8649659115900594\n",
      "Accuracy test 0.8374358974358974\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.29      0.40       365\n",
      "           1       0.85      0.96      0.91      1585\n",
      "\n",
      "    accuracy                           0.84      1950\n",
      "   macro avg       0.75      0.63      0.65      1950\n",
      "weighted avg       0.82      0.84      0.81      1950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_clas = xgboost.XGBRFClassifier(random_state=42,use_label_encoder=False)\n",
    "\n",
    "xgb_clas.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_clas.predict(X_test)\n",
    "\n",
    "print(\"Accuracy train\",xgb_clas.score(X_train, y_train))\n",
    "print(\"Accuracy test\",xgb_clas.score(X_test, y_test))\n",
    "print(classification_report(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "[12:27:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.8396761388391345\n",
      "{'subsample': 0.8, 'min_child_weight': 1, 'gamma': 0.5}\n"
     ]
    }
   ],
   "source": [
    "xgboost_tuning = xgboost.XGBRFClassifier(random_state=42,use_label_encoder=False)\n",
    "\n",
    "min_child_weight=[1, 5, 10]\n",
    "gamma=[0.5, 1, 1.5, 2, 5]\n",
    "subsample=[0.6, 0.8, 1.0]\n",
    "\n",
    "\n",
    "\n",
    "hyperF = dict(min_child_weight=min_child_weight,gamma=gamma,subsample=subsample)\n",
    "\n",
    "gridF = RandomizedSearchCV(xgboost_tuning, hyperF, cv = 10, verbose = 1, \n",
    "                      n_jobs = -1)\n",
    "bestF = gridF.fit(X_train, y_train)\n",
    "\n",
    "print(bestF.best_score_)\n",
    "print(bestF.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:27:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy train 0.8605674070815923\n",
      "Accuracy test 0.8353846153846154\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.27      0.38       365\n",
      "           1       0.85      0.97      0.91      1585\n",
      "\n",
      "    accuracy                           0.84      1950\n",
      "   macro avg       0.75      0.62      0.64      1950\n",
      "weighted avg       0.81      0.84      0.81      1950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_clas = xgboost.XGBRFClassifier(random_state=42,use_label_encoder=False,subsample=1,gamma=1,min_child_weight=1)\n",
    "\n",
    "xgb_clas.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_clas.predict(X_test)\n",
    "\n",
    "print(\"Accuracy train\",xgb_clas.score(X_train, y_train))\n",
    "print(\"Accuracy test\",xgb_clas.score(X_test, y_test))\n",
    "print(classification_report(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train 0.8143831097426875\n",
      "Accuracy test 0.8215384615384616\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.16      0.26       365\n",
      "           1       0.83      0.97      0.90      1585\n",
      "\n",
      "    accuracy                           0.82      1950\n",
      "   macro avg       0.71      0.57      0.58      1950\n",
      "weighted avg       0.79      0.82      0.78      1950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbct = GradientBoostingClassifier(max_depth=2,n_estimators=3,learning_rate=1.0,random_state=42)\n",
    "\n",
    "gbct.fit(X_train, y_train)\n",
    "y_pred_gbct = gbct.predict(X_test)\n",
    "\n",
    "print(\"Accuracy train\",gbct.score(X_train, y_train))\n",
    "print(\"Accuracy test\",gbct.score(X_test, y_test))\n",
    "print(classification_report(y_test, y_pred_gbct))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GradientBoostClassifier hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "0.8306554678801374\n",
      "{'subsample': 0.7, 'n_estimators': 20, 'min_samples_leaf': 6, 'max_depth': 4, 'learning_rate': 0.5}\n"
     ]
    }
   ],
   "source": [
    "gbct = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "\n",
    "learning_rate=[0.01,0.05,0.1,1,0.5]\n",
    "max_depth=[3,4,5]\n",
    "min_samples_leaf=[4,5,6]\n",
    "subsample=[0.6,0.7,0.8]\n",
    "n_estimators=[5,10,15,20]\n",
    "\n",
    "\n",
    "\n",
    "hyperF = dict(learning_rate=learning_rate,max_depth=max_depth,min_samples_leaf=min_samples_leaf,subsample=subsample,n_estimators=n_estimators)\n",
    "\n",
    "gridF = RandomizedSearchCV(gbct, hyperF, cv = 10, verbose = 1, \n",
    "                      n_jobs = -1)\n",
    "bestF = gridF.fit(X_train, y_train)\n",
    "\n",
    "print(bestF.best_score_)\n",
    "print(bestF.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train 0.7994281944138992\n",
      "Accuracy test 0.8128205128205128\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       365\n",
      "           1       0.81      1.00      0.90      1585\n",
      "\n",
      "    accuracy                           0.81      1950\n",
      "   macro avg       0.41      0.50      0.45      1950\n",
      "weighted avg       0.66      0.81      0.73      1950\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Héctor\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Héctor\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Héctor\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "gbct = GradientBoostingClassifier(subsample=0.6,n_estimators=5,min_samples_leaf=5,max_depth=5,learning_rate=0.05,random_state=42)\n",
    "\n",
    "gbct.fit(X_train, y_train)\n",
    "y_pred_gbct = gbct.predict(X_test)\n",
    "\n",
    "print(\"Accuracy train\",gbct.score(X_train, y_train))\n",
    "print(\"Accuracy test\",gbct.score(X_test, y_test))\n",
    "print(classification_report(y_test, y_pred_gbct))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train 0.8851990323290081\n",
      "Accuracy test 0.8466666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.38      0.48       365\n",
      "           1       0.87      0.96      0.91      1585\n",
      "\n",
      "    accuracy                           0.85      1950\n",
      "   macro avg       0.76      0.67      0.69      1950\n",
      "weighted avg       0.83      0.85      0.83      1950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(C=100)\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred_svc = svc.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Accuracy train\",svc.score(X_train, y_train))\n",
    "print(\"Accuracy test\",svc.score(X_test, y_test))\n",
    "print(classification_report(y_test, y_pred_svc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Héctor\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_search.py:296: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8361562666408482\n",
      "{'C': 10}\n"
     ]
    }
   ],
   "source": [
    "svc_tuning = SVC(random_state=42)\n",
    "\n",
    "C = [1,10,100,1000]\n",
    "\n",
    "\n",
    "\n",
    "hyperF = dict(C=C)\n",
    "\n",
    "gridF = RandomizedSearchCV(svc_tuning, hyperF, cv = 10, verbose = 1, \n",
    "                      n_jobs = -1)\n",
    "bestF = gridF.fit(X_train, y_train)\n",
    "\n",
    "print(bestF.best_score_)\n",
    "print(bestF.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train 0.9879041126017154\n",
      "Accuracy test 0.861025641025641\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.57      0.60       365\n",
      "           1       0.90      0.93      0.92      1585\n",
      "\n",
      "    accuracy                           0.86      1950\n",
      "   macro avg       0.77      0.75      0.76      1950\n",
      "weighted avg       0.86      0.86      0.86      1950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(C=10,kernel='rbf',gamma=1)\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred_svc = svc.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Accuracy train\",svc.score(X_train, y_train))\n",
    "print(\"Accuracy test\",svc.score(X_test, y_test))\n",
    "print(classification_report(y_test, y_pred_svc))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "be6eeff857b0dd6c25c8f04c5088da4d3d721249ca9fc1768b1bbff2b0e44d85"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
